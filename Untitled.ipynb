{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3949fce7",
   "metadata": {},
   "source": [
    "What is a fully connected network (FCN for short)?\n",
    "\n",
    "A fully connected network is a type of artifical neural network whose structure consists of layers connected to other layers by the neurons/nodes in each layer. For example, if there is a FCN that has 3 layers with layer 1 having 10 neurons, layer 2 having 26 neurons, and layer 3 having 14 neurons. In this example, each one of the neurons in layer 1 has a connection to every single neuron in layer 2 and the same concept holds true for the relation between layer 2 and layer 3. What is also interesting is that you can figure out the amount of connections that are there between two layers. The equation for that the N1*(N1*N2) where N1 is the number of neurons in the layer on the left and N2 is the number of neurons on the right.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d3188284",
   "metadata": {},
   "source": [
    "How do Fully Connected Networks work?\n",
    "\n",
    "FCNs work by having a neuron/perceptron apply a linear transformation to the input vector through a weight matrix. Then a non-linear transformation is applied to the product of the input vector and weight matrix through a non linear activation function (show equation image).\n",
    "\n",
    "Basically, we are taking the dot product of the weight matrix W and the input vector x. Then the bias term W0 will be added inside the non linear function. (A Bias term is a disproportionate weight in favor or against an idea or thing). In even simpler terms, we are doing vector multiplication. For example, we have an input vector of 1x9 and a weight matrix of 9x4. We will take the dot product of (1x9) and (9x4) and then apply the non-linear transformation with the activation function f to get an output vector of (1x4) (show the second image before the example and the third fcl image after the example)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "66e36a85",
   "metadata": {},
   "source": [
    "How does a FCN differ from a CNN?\n",
    "\n",
    "The biggest difference from what I seen online in doing my own research is that FCNs are structurally agnostic meaning that they don't make any special assumption about the input given whereas a CNN is designed to assume that the input are specifically images. \n",
    "\n",
    "This broad assumption that FCNs have can be quite useful if one wants to train different data. However, due to the broad assumption, the performance of a FCN is not a great compared to a neural network that is designed for a specific kind of input, like a CNN. Another advantage is that FCNs have more expressive power compared to CNNs due to convolution being linear.\n",
    "\n",
    "The specific focus that a CNN is designed for is quite useful as one can process the input of images quite quickly compared to a FCN. However, the main disadvantage of this type of neural network is that you can only train the network on images and nothing else which is where the FCN comes in. Another advantage is that CNNs seem to be more efficient in utilizing their parameters. FCNs tend to require a greater number of parameters to compete to an equivalent CNN.\n",
    "\n",
    "So, overall, depending on your needs, a FCN can be better than a CNN and vice versa."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40f6d341",
   "metadata": {},
   "source": [
    "What are some ways that FCNs can be used?\n",
    "\n",
    "In searching for good real world examples of FCNs as a way to better explain FCNs, I came across three different papers that peaked my interest. \n",
    "\n",
    "The first one is called Intra Prediction using Fully Connected Network for Video Coding which is by Jihao Li, Bin Li, Jizheng Xu, and Ruiqin Xiong. \n",
    "\n",
    "The second one is called Fully Connected Network on Noncompact Symmetric Space and Ridgelet Transform based on Helgason Fourier Analysis which is by Sho Sonoda, Isao Ishikawa, and Masahiro Ikeda.\n",
    "\n",
    "The third one is called How Far Can We go Without Convolution: Improving Fully Connected Networks which is by Zhouhan Lin, Roland Memisevic, and Kishore Konda.\n",
    "\n",
    "I will go over the three world examples after my example code."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "abc48d1f",
   "metadata": {},
   "source": [
    "The goal of my example code is to train a FCN to classify handwritten digits from 0-9. For my code, I am using the Keras library mainly instead of PyTorch because I have tried to get PyTorch to work on my machine and it seems to not work (don't know what went wrong, but it probably is user error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "55279671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ab38454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the fully connected neural network model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad857b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the device for training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f967b5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "input_size = 784  # Input size of MNIST dataset (28x28 pixels)\n",
    "hidden_size = 500\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c4fbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "358ebf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the neural network\n",
    "model = NeuralNetwork(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "977550a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the neural network\n",
    "total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Reshape images to (batch_size, input_size)\n",
    "        images = images.reshape(-1, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{total_steps}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b4368c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NeuralNetwork' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Training loop\u001b[39;00m\n\u001b[1;32m      2\u001b[0m train_loader \u001b[39m=\u001b[39m model\n\u001b[0;32m----> 3\u001b[0m train(model, train_loader, optimizer, criterion, num_epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[33], line 5\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, criterion, num_epochs)\u001b[0m\n\u001b[1;32m      3\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 5\u001b[0m     \u001b[39mfor\u001b[39;00m inputs, targets \u001b[39min\u001b[39;00m train_loader:\n\u001b[1;32m      6\u001b[0m         optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m      7\u001b[0m         outputs \u001b[39m=\u001b[39m model(inputs)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NeuralNetwork' object is not iterable"
     ]
    }
   ],
   "source": [
    "# Test the neural network\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the network on the 10000 test images: {(100 * correct / total):.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
